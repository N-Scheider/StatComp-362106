---
title: "Assignment 2"
author: "Noah Scheider"
date: "October 2, 2022"
header-includes: \usepackage{bbm}
output: html_document
---

Having no clue about how to present results in R Markdown and even less how to produce a HTML report I browsed the internet and - lucky me - I found an introduction to it on [RStudio](https://rmarkdown.rstudio.com/articles_intro.html)

## Forword

Before importing any R code and writing the Markdown file I tried my best to follow the advice suggested in the beginning of the second lecture on "**Good Coding Practices**". Therefore I hopefully won't need to change any of my code when importing it to this .Rmd file. Description of the exercises and detailed ideas on its implementation will be added to the Markdown code. Explanation to the R code is obviously in the R script. In case of reproduction of this Markdown file it is necessary to install the package RMarkdown, knitr, yaml via  *install.packages("rmarkdown"), install.packages("knitr"), install.packages("yaml")*.


## Exercise 1.1 - Dependency of standard normal distribution

Freedman(2009) Statistical Models, Example 4, p. 75:
Suppose $Y$ consists of $100$ independent $\mathcal{N}(0, 1)$ random variables. This is pure noise. Let $X \in \mathbb{R}^{100\times50}$ be the design matrix with independent $\mathcal{N}(0, 1)$ variables (just more noise). We regress Y on X (i.e. no intercept). The coefficient of determination $R^{2}$ will be about $50/100=0.5$. Suppose we test each of the $50$ coefficients at the $10 %$ level and keep only the “significant” variables. There will be about $50 \times 0.1 = 5$ keepers (just by chance). Running the regression on the keepers only (again, without intercept), we are likely to get a decent $R^{2}$ (like $0.2$ – decent by the social-science standards) and dazzling t-statistics. Run a couple of simulations and see for yourself.

```{r}
y <- rnorm(100)
x <- matrix(rnorm(5000), nrow = 100)
linear_model <- lm(y ~ 0 + x)
cat("R squared error in initial model:", summary(linear_model)$r.squared)

x_sign <- x[,which(summary(linear_model)$coefficients[,"Pr(>|t|)"]<0.05)]
linear_model_sign <- lm(y ~ 0 + x_sign)
cat("R squared error in model with sign coef:", summary(linear_model_sign)$r.squared)
```

## Exercise 1.2 - Peeking

The “Example of Peeking” above is an example of a small simulation study, checking whether a designed test strategy respects the nominal level $\alpha = 0.05$ or not. Incorporate further levels of peeking in order to mimic the power-posing study.

```{r, echo=FALSE}
# Idea 1: Get the n most significant p-values and compute the R squared error of their RV
n = 10
p_limit <- sort(summary(linear_model)$coefficients[,4])[n]
x_sign2 <- x[,which(summary(linear_model)$coefficients[,"Pr(>|t|)"]<p_limit)]
linear_model_sign2 <- lm(y ~ 0 + x_sign2)
cat("R squared error in model with sign coef:", summary(linear_model_sign2)$r.squared)
```

The idea for this peeking example relies on averaging the number of significant (peeked) columns and the taking the mean of this average, i.e. a double mean.
```{r}
# Idea 2 (lecture): Append RV
peeking <- function(X_rv_n = 5000, X_rv_rows = 100, ext = 45){
  X_rv <- matrix(rnorm(X_rv_n), nrow = X_rv_rows)
  #  creating function to get T sizes of columns without and with appending new RV
  Tsize_func <- function(vec){
    return(mean(vec)/sd(vec)*sqrt(length(vec)))
  }
  Tsize_func_app <- function(vec){
    vec <- append(vec, rnorm(ext))
    return(mean(vec)/sd(vec)*sqrt(length(vec)))
  }
  # Preserve significant columns and peek insignificant ones
  Xvec_Tstats <- mapply(Tsize_func, asplit(X_rv, 2))
  ind <- which(Xvec_Tstats <= qt(p = 0.975, df = X_rv_rows-1))
  Xvec_Tstats2 <- mapply(Tsize_func_app, asplit(X_rv[,ind], 2))
  Xvec_Tstats <- replace(Xvec_Tstats, ind, Xvec_Tstats2)
  return(mean(I(abs(Xvec_Tstats) > qnorm(0.975))))
}

mean(replicate(100, peeking()))
```

## Exercise 2 - Markdown and HTML

That's the report, hopefully it passes the Assignment. Unfortunately, I still had to change a bit of code when importing it. Last but not least, I kept in mind that *echo=FALSE* hides the code to a certain output and *eval=FALSE* shows the code but not the output.
